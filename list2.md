# **AIÂ Development Resource Master List (UnifiedÂ EditionÂ â€“Â AprilÂ 18Â 2025)**

> *Living document originally compiled for Harvard, MIT, and Oxford programsâ€”now merged into a single, deduplicated reference.*  
> *Contributions via pullâ€‘request are welcome.*

---

## ğŸ“‘ TableÂ ofÂ Contents
1. ğŸ›ï¸ Historical Foundations & Core Concepts  
2. ğŸš€ Frontier Models (2025â€‘Q2)  
3. ğŸ› ï¸ Ecosystem & Tooling  
4. ğŸ§‘â€ğŸ”¬ Research & Thought Leadership  
5. ğŸŒ Applied CaseÂ Studies  
6. âš–ï¸ Ethics, SafetyÂ & Policy  
7. ğŸ“ Student Opportunities  
8. ğŸ“œ Appendices & FurtherÂ Reading  

---

## 1Â | ğŸ›ï¸ Historical FoundationsÂ & Core Concepts
### 1.1Â Interactive TimelinesÂ & Visualizers
- **AIÂ Timeline:** <https://ai-timeline.org/>  
- **LLMÂ 3â€‘D Walkthrough:** <https://bbycroft.net/llm>  
- **TransformerÂ Explainer:** <https://poloclub.github.io/transformer-explainer/>  
- **Promptâ€‘Chaining Primer:** <https://www.agentrecipes.com/prompt-chaining>

### 1.2Â Training Pipeline (Preâ€‘trainÂ â†’ Fineâ€‘tuneÂ â†’ RLHF)
| Stage | Classic definition | Typical recipe | 2025 upgrade |
|---|---|---|---|
| **Preâ€‘training** | Train on *massive* unlabeled corpora to learn general language + world knowledge. | Trillions of tokens, nextâ€‘token prediction over web + code; dense or MoE. | Data curriculum (RefinedWeb, Synthoid), inferenceâ€‘aware training (OpenAIâ€¯oâ€‘series). |
| **Fineâ€‘tuning** | Adapt the base model to a specific domain/task with smaller labeled data. | LoRAâ€¯/â€¯QLoRA on medical Q&A, code, policy docs. | Multiâ€‘head PEFT; Sparse LoRA for large MoE shards. |
| **RLHF** | Collect human preference pairs â†’ reward model â†’ RL (usually PPO) to align outputs. | 5â€“10â€¯k preference pairs, Proximal Policy Optimization. | **RLAIF** (AI feedback), **DPO/ORPO** skip RL loop; cheaper, faster. |

> **NoteÂ â€”Â â€œRLHFâ€ now often means RLAIF or DPO/ORPO:** reward signals can come from strong critic models instead of humans, or the model can be aligned directly on preference pairs without a PPO loop.
 

### 1.3Â Retrievalâ€‘Augmented Generation (RAG) Variants  
| Variant | Core idea | When it shines |
|---|---|---|
| **PlainÂ RAG** | Vector similarity search over text chunks | General chatbots & Q&A |
| **GraphÂ RAG** | Build a knowledge graph, traverse edges, then retrieve passages | Multiâ€‘hop reasoning, codebases |
| **TabularÂ / SQLâ€¯RAG** | Treat rows & columns as chunks; combine SQL and embeddings | Finance, analytics, CSVâ€‘heavy corpora |
| **HybridÂ RAG** | Combine lexical BM25 with dense vectors; hybrid scoring | Legal, medicalâ€”domains with exact terms |
| **HierarchicalÂ RAG** | Retrieve coarse sections first, then subâ€‘chunks | Long PDFs, textbooks, RFCs |
| **Contextâ€‘CompressionÂ RAG** | Retrieve â†’ summarize/compress â†’ feed to model | Tokenâ€‘efficient answers on smallâ€‘ctx LLMs |
| **Agentic / Toolâ€‘RAG** | Retrieval step wrapped inside an agent that can also call tools | Dynamic workflows e.g., â€œlookup â†’ calculateâ€ |
| **MultimodalÂ RAG** | Index images/audio/video embeddings alongside text | Diagrams, lecture slides, podcasts |

<details>
<summary>ğŸ› ï¸Â How each RAG variant works â–¸</summary>

* **Plainâ€¯RAGâ€¯(baseâ€‘line)** â€“ Embed â†’ similarity search â†’ stuff context. Generalâ€‘purpose and fast.  
* **Graphâ€¯RAG** â€“ Build a knowledge graph (nodesâ€¯=â€¯entities / code symbols), follow edges, then fetch passages. Excels at multiâ€‘hop reasoning and large codebases.  
* **TabularÂ /Â SQLâ€¯RAG** â€“ Treat rows & columns as chunks; combine SQL filters with vector search. Perfect for finance, analytics, and onâ€‘chain data.  
* **Hybridâ€¯RAG** â€“ Run lexical BM25 **plus** denseâ€‘vector search, then rank/merge. Retains exactâ€‘term recallâ€”great for legal or medical corpora.  
* **Hierarchicalâ€¯RAG** â€“ Retrieve coarse sections (chapters, headings) first, then drill into subâ€‘chunks. Keeps context coherent for huge PDFs or RFCs.  
* **Contextâ€‘Compressionâ€¯RAG** â€“ Retrieve â†’ summarize/compress â†’ feed to the model. Saves tokens and latency on smallâ€‘context LLMs.  
* **AgenticÂ /Â Toolâ€‘RAG** â€“ Retrieval step is wrapped inside an agent that can also invoke tools (e.g., calculators, APIs) and iterate. Enables dynamic workflows.  
* **Multimodalâ€¯RAG** â€“ Index image/audio/video embeddings alongside text so the same query can pull diagrams, screenshots, or podcasts as evidence.

</details>

---

## 2Â | ğŸš€ Frontier Models (2025â€‘Q2)

| Vendor | Model | CtxÂ Window | Reasoning? | Architecture | Highlights | MTâ€‘BenchÂ¹ | MMLUÂ² |
|---|---|---|---|---|---|---|---|
| **OpenAI** | **o3** |Â 128â€¯k | âœ… | DenseÂ Transf. | Bestâ€‘inâ€‘class reasoning & vision | 9.2 | 87.5 |
| | **o4â€‘mini** |Â 128â€¯k | âœ… | DenseÂ Transf. | Faster & cheaper than o3 | 8.8 | 82.0 |
| | **o4â€‘miniâ€‘high** |Â 128â€¯k | âœ… | DenseÂ Transf. | Higher limits, same latency | 9.0 | 84.0 |
| | **GPTâ€‘4o** |Â 128â€¯k | âœ… | Multimodal Dense | Replaces GPTâ€‘4 in ChatGPT onÂ 30â€¯Aprâ€¯2025 | 9.4 | 86.8 |
| | **GPTâ€‘4.5 â€œOrionâ€** |Â 256â€¯k | âœ… | DenseÂ Transf. | Research preview (17â€¯Marâ€¯2025) | 9.6 | 88.2 |
| **Anthropic** | **ClaudeÂ 3.7Â Sonnet** |Â 200â€¯k | âœ… | HybridÂ (MoEÂ +Â Dense) | STEM/code specialist | 8.7 | 83.5 |
| **Google** | **GeminiÂ 2.5Â Flash** |Â 1â€¯M | âœ…* | MoE | â€œThinking budgetsâ€ cut costÂ >â€¯6Ã— | 8.3 | 77.9 |
| | **GeminiÂ 1.5Â Pro** |Â 1â€¯M | âœ… | MoE | Longâ€‘context pioneer | 8.9 | 86.0 |
| **DeepSeek** | **DeepSeekÂ V3Â Chat** |Â 128â€¯k | âœ… | DenseÂ Transf. | +50â€¯% reasoning vs V2 | 8.4 | 80.5 |
| **Meta** | **Llamaâ€‘3Â 70B** |Â 8â€‘128â€¯k | âœ… | DenseÂ Transf. | Openâ€‘weights, commercially usable | 7.9 | 73.0 |
| **Mistral** | **MixtralÂ 8Ã—22B** |Â 64â€¯k | âœ… | SparseÂ MoE | SoTA open model | 8.1 | 78.0 |
| **Alibaba** | **QwenÂ 2.5â€‘1M** |Â 1â€¯M | âœ… | MoE | First OSS model with 1â€¯MÂ tokens | 8.4 | 79.5 |

<sub>Â¹Â MTâ€‘Bench (10â€¯=â€¯max) compiled from vendor or community MTâ€‘Bench dashboards, Aprâ€¯2025.  
Â²Â MMLU (0â€‘100). Scores vary Â±0.3 depending on evaluation harness.</sub>

### 2.1Â ğŸ§©Â Model Architecture Cheatâ€‘Sheet

| Architecture | Core idea | Popular 2025 examples | Strengths | Tradeâ€‘offs |
|---|---|---|---|---|
| **Dense Transformer** | Every token attends to every other via full attention; parameters fully active each step. | GPTâ€‘4o, Llamaâ€‘3â€¯70B, DeepSeekâ€¯V3 | Strong generalization; mature tooling. | Expensive compute; quadratic memory. |
| **SparseÂ Mixtureâ€‘ofâ€‘ExpertsÂ (MoE)** | Router sends each token to a small subset of expert Multilayer Perceptrons (MLPs) â†’ only ~10â€‘25â€¯% parameters active. | Mixtralâ€¯8Ã—22B, OpenAIâ€¯oâ€‘series, Qwenâ€¯2.5â€‘1M | Higher parameter count at lower FLOPs; easy scaling. | Router complexity; loadâ€‘balancing issues. |
| **Hybrid DenseÂ +Â MoE (Hierarchical)** | Alternate dense layers with MoE blocks or blend both paths. | Claudeâ€¯3.7â€¯Sonnet, Geminiâ€¯1.5â€¯Pro | Combines dense robustness with MoE efficiency. | Implementation complexity; tuning routerâ€‘dense balance. |
| **Stateâ€‘Space ModelsÂ (SSM)** | Replace attention with linear stateâ€‘space kernels (convolutional recursion). | Mambaâ€¯2.8B, S4â€‘X, RWKVâ€‘5 | O(T) memory, handles >4â€¯M tokens. | Still experimental; fewer inference libraries. |
| **Retrievalâ€‘Augmented Autoregressive (Retroâ€‘style)** | Decoder consults external vector DB or memory for nearest passages midâ€‘generation. | DeepMindâ€¯RETRO, Alibabaâ€¯Giraffe | Builtâ€‘in factual recall and smaller base model. | Requires datastore infra; retrieval latency. |
| **StructuredÂ ExpertÂ (GQA / MQA)** | Multiâ€‘query or groupedâ€‘query attention reduces KV size; acts like lightweight â€œexpert routing.â€ | Llamaâ€‘3, Mistralâ€‘7B | Faster inference, smaller KV cache. | Slight accuracy tradeâ€‘off on small models. |
| **DiffusionÂ Transformer (DiT)** | Use diffusion denoising steps with transformer backbone for images. | Stableâ€¯DiffusionÂ 3Â DiT, DeepFloydâ€¯IF | Highâ€‘quality image generation. | Not suited for language tasks. |

 > *Cheatâ€‘sheet takeaway:* most frontier LLMs are now **Sparse MoE or Hybrid**, balancing capacity with compute. Dense transformers dominate subâ€‘30â€¯Bâ€¯param models, while SSMs and Retroâ€‘style hybrids target ultraâ€‘long context and factual recall.
 

 <details>
 <summary>ğŸ”Â Mixtureâ€‘ofâ€‘ExpertsÂ (MoE) â€” How expert MLPs work â–¸</summary>
 
 **Expert MLPs = specialist subnetworks**
 
 * **MLP = Multilayer Perceptron** (2â€‘3 fullyâ€‘connected layers).  
 * In classic transformers, every token passes through the *same* MLP block.  
 * In an **MoE layer** you have *many* MLPs (the â€œexpertsâ€). A *router* decides which small subset of experts (usually 1â€‘2) process each token.
 
 ```
 Token â†’ Router â†’ ExpertÂ 3 & ExpertÂ 7 â†’ Combine â†’ Next layer
 ```
 
 ### Why bother?
 
 | Benefit | What it means |
 |---|---|
 | **Efficient scaling** | Billions of parameters, but each forward pass touches only ~10â€‘20â€¯% of them. |
 | **Specialization** | Experts learn subâ€‘skills (math vs. dialog, etc.). |
 | **Modularity** | You can add experts without retraining the whole model. |
 
 ### Example setups
 
 | Model | Expert config | Notes |
 |---|---|---|
 | MixtralÂ 8Ã—22B | 8 experts, 2 active/token | Openâ€‘weights; community favourite. |
 | OpenAIâ€¯oâ€‘series (o3/o4â€‘mini) | *Undisclosed* MoE layers | Used to hit high reasoning at lower cost. |
 | Geminiâ€¯1.5Â Pro | Hierarchical MoE | Longâ€‘context, 1â€¯M tokens. |
 
 
 </details>
 
 ---

## 3Â | ğŸ› ï¸ EcosystemÂ & Tooling

### 3.1Â Core Platform for Experiments
| Platform | Link | Purpose |
|---|---|---|
| **Andromeda Protocol Testnet** | https://app.testnet.andromedaprotocol.io/ | Decentralized sandbox for AIÃ—Blockchain experiments |

### 3.2Â AIÂ SearchÂ Engines
| Engine | Differentiation | Link |
|---|---|---|
| Perplexity | Academic citations, live web | https://perplexity.ai |
| Scira | OSS Perplexityâ€‘style search | https://scira.ai/about |
| You.com | Customizable multiâ€‘agent UX | https://you.com |
| Phind | Developerâ€‘centric | https://phind.com |
| Komo | Mindâ€‘map UI | https://komo.ai |
| GeminiÂ Search | Google multimodal reasoning | https://gemini.google.com |
| Copilot (Bing) | Microsoft ecosystem | https://copilot.microsoft.com |

### 3.3Â AIâ€‘Infused Coding Tools & IDEs

| Category | Tool | What it does | Link |
|---|---|---|---|
| IDE | Cursor | Contextâ€‘aware IDE built around LLM pairâ€‘programming | https://www.cursor.sh |
| IDE | VSÂ Code | Extensible openâ€‘source editor with vast AI plugâ€‘in ecosystem | https://code.visualstudio.com/ |
| IDE | JetBrainsÂ AIÂ Assistant | Adds the â€œJunieâ€ agent + context menus across IntelliJ family | https://www.jetbrains.com/ai/ |
| IDE | GoogleÂ IDX | Cloud IDE that autoâ€‘completes full functions & handles deploys | https://idx.dev |
| IDE | WindsurfÂ Editor | Local agentâ€‘powered IDE (acquired Codeium for autocomplete) | https://windsurf.com |
| IDEÂ Ext | RepoÂ Prompt | VSÂ Code extension: wraps entire repo into a single LLM prompt | https://marketplace.visualstudio.com/items?itemName=taowen.repo-to-prompt |
| Oneâ€‘Shot Agent | VercelÂ V0 | Generates productionâ€‘ready React/Next UI from a prompt | https://v0.dev |
| Oneâ€‘Shot Agent | Replit | Browser IDE with â€œReplitÂ AIâ€ fullâ€‘stack agent scaffold | https://replit.com |
| Oneâ€‘Shot Agent | bolt.new | Creates SaaS backâ€‘ends + dashboards in one command | https://bolt.new |
| Oneâ€‘Shot Agent | Lovable.dev | Dragâ€‘andâ€‘drop AI internalâ€‘tool generator | https://lovable.dev |
| Oneâ€‘Shot Agent | Llamacoder | Local fullâ€‘stack agent built on TogetherÂ AI models | https://github.com/TogetherAI/llamacoder |
| Plugâ€‘in | Continue | OSS multiâ€‘model copilot for VSâ€¯Code & JetBrains | https://www.continue.dev |
| Plugâ€‘in | Cline | Autonomous coding agent plugâ€‘in w/ Model Context Protocol | https://cline.bot |
| Plugâ€‘in | AIÂ Commit | Generates git commit messages from staged diffs | https://marketplace.visualstudio.com/items?itemName=Sitoi.ai-commit |
| Plugâ€‘in | CodeViz | Interactive callâ€‘graph & architecture explorer | https://marketplace.visualstudio.com/items?itemName=codeviz.codeviz |
| Plugâ€‘in | TabbyÂ Autocomplete | Selfâ€‘hosted, openâ€‘source autocomplete server | https://github.com/TabbyML/tabby |
| CLI | Warp | Modern terminal with naturalâ€‘language command search | https://warp.dev |
| CLI | Aider | AI-powered command-line assistant | https://aider.chat |
| CLI | ClaudeÂ Code | Code generation and debugging assistant | https://github.com/anthropic/claude-code |
| CLI | OpenAIÂ CodexÂ CLI | Command-line interface for OpenAI Codex | https://github.com/openai/codex-cli |

### 3.4Â Openâ€‘Source Utilities & Creative Suite

| Category | Tool | What it does | Link |
|---|---|---|---|
| DesktopÂ Chat | MSTY | Offline desktop chat app for local/OSS models with branching and RAG | https://msty.app |
| DesktopÂ Chat | Chorus | Chat with multiple LLMs and autoâ€‘crossâ€‘check answers | https://chorus.sh |
| Utility | Ollama | Local model runner/manager (macOS, Linux) | https://ollama.com |
| Utility | LMÂ Studio | GUI playground for downloading, running, and prompting local LLMs | https://lmstudio.ai |
| Utility | AnythingLLM | Selfâ€‘hosted RAG stack with plugâ€‘andâ€‘play embeddings | https://useanything.com |
| Visual | MidJourney | Highâ€‘quality image generation via Discord | https://www.midjourney.com |
| Visual | Krea | Realâ€‘time generative image & reference search | https://www.krea.ai |
| Visual | Ideogram | Textâ€‘centric image generation (typography aware) | https://ideogram.ai |
| Visual | DALLÂ·EÂ 3 | OpenAI textâ€‘toâ€‘image model (web/API) | https://openai.com/dall-e-3 |
| Visual | RunwayÂ ML | AI video & image creation suite | https://runwayml.com |
| Visual | ComfyUI | Nodeâ€‘based Stable Diffusion workflow GUI | https://github.com/comfyanonymous/ComfyUI |
| Audio/Video | Suno | Generate full songs from text prompts | https://suno.com |
| Audio/Video | Udio | Textâ€‘toâ€‘music generation platform | https://www.udio.com |
| Audio/Video | Descript | AIâ€‘assisted audio & video editing | https://www.descript.com |
| Audio/Video | AdobeÂ Firefly | Generative image and text effects in Creative Cloud | https://firefly.adobe.com |
| Audio/Video | AdobeÂ PremiereÂ Pro | Video editor with AI background removal & speech cleanâ€‘up | https://www.adobe.com/products/premiere.html |

---

## 4Â | ğŸ§‘â€ğŸ”¬ ResearchÂ & Thought Leadership
Follow on **X/Twitter** with notifications; mine quality replies for other high-signal accounts.

| Account | FocusÂ / Role | WhyÂ Follow |
|---|---|---|
| **[AndrejÂ KarpathyÂ (@karpathy)](https://x.com/karpathy)** | Founder Tiny Corp; exâ€‘OpenAI/Tesla, AI educator & code explainer | Deepâ€‘dive threads & code walkâ€‘throughs |
| **[DemisÂ HassabisÂ (@demishassabis)](https://x.com/demishassabis)** | Coâ€‘founder & CEO, GoogleÂ DeepMind; neuroscientistâ€‘turnedâ€‘AI pioneer | Cuttingâ€‘edge research drops |
| **[GeoffreyÂ HintonÂ (@geoffreyhinton)](https://x.com/geoffreyhinton)** | â€œGodfather of deep learningâ€; now focuses on AIâ€‘risk research | Brainâ€‘inspired models & safety |
| **[YoshuaÂ BengioÂ (@yoshuabengio)](https://x.com/yoshuabengio)** | Mila founder; GFlowNet & alignment pioneer | Cuttingâ€‘edge alignment papers |
| **[YannicÂ KilcherÂ (@ykilcher)](https://x.com/ykilcher)** | YouTuber who decodes new papers into plain English | Weekly paper explainers |
| **[JeffÂ DeanÂ (@JeffDean)](https://x.com/JeffDean)** | Google DeepMind Chief Scientist; exâ€‘GoogleÂ Research SVP | Modelâ€‘scaling insights |
| **[EmilyÂ BenderÂ (@emilymbender)](https://x.com/emilymbender)** | UW linguist; coâ€‘author â€œStochastic Parrotsâ€; dataâ€‘ethics critic | Ethics & dataset discourse |
| **[JeremyÂ HowardÂ (@jeremyphoward)](https://x.com/jeremyphoward)** | fast.ai coâ€‘founder; practical ML educator | Handsâ€‘on notebooks & courses |
| **[StellaÂ BidermanÂ (@stellabiderman)](https://x.com/stellabiderman)** | EleutherAI researcher; openâ€‘weights advocate (Pythia, GPTâ€‘NeoX) | Openâ€‘model scaling laws |
| **[EmadÂ MostaqueÂ (@EMostaque)](https://x.com/EMostaque)** | StabilityÂ AI founder; champion of open generative media | Model release announcements |
| **[JimÂ FanÂ (@DrJimFan)](https://x.com/DrJimFan)** | Sr. Research Scientist, NVIDIA; leads embodiedâ€‘agent group (GR00T) | Robotics insights |
| **[TekniumÂ (@Teknium1)](https://x.com/Teknium1)** | Coâ€‘founder / research lead at NousÂ Research; openâ€‘weights evaluator | Frontierâ€‘model benchmarking |
| **[RobertÂ ScobleÂ (@scobleizer)](https://x.com/scobleizer)** | Siliconâ€‘Valley tech scout; curates large lists of AI startups & demos | Longâ€‘horizon spotting |
| **[LoganÂ KilpatrickÂ (@OfficialLoganK)](https://x.com/OfficialLoganK)** | DevRel Lead for GoogleÂ AIÂ Studio & Gemini API | Productization threads |
| **[GaryÂ MarcusÂ (@garymarcus)](https://x.com/garymarcus)** | NYU cognitive scientist & AI skeptic; policy commentator | Hypeâ€‘balanced takes |
| **[ShawÂ (@shawmakesmagic)](https://x.com/shawmakesmagic)** | Creator of ElizaOS agent framework; agentic tooling for Web3 | Decentralizedâ€‘agent ecosystem |
| **[YannÂ LeCunÂ (@ylecun)](https://x.com/ylecun)** | Meta ChiefÂ AIÂ Scientist; Turing Award winner, convâ€‘net pioneer | EBMs + open research |
| **[AndrewÂ NgÂ (@AndrewYNg)](https://x.com/AndrewYNg)** | Founder DeepLearning.AI / LandingÂ AI; MOOC & enterprise AI guru | Democratizing AI |
| **[IanÂ GoodfellowÂ (@goodfellow_ian)](https://x.com/goodfellow_ian)** | Director of ML, Apple SPG; inventor of GANs | Generative pioneer |
| **[SamÂ AltmanÂ (@sama)](https://x.com/sama)** | Coâ€‘founder & CEO, OpenAI; investor & policy advocate | Macro ethics + product |
| **[JohnÂ CarmackÂ (@ID_AA_Carmack)](https://x.com/ID_AA_Carmack)** | Legendary game dev; independent AGI researcher focused on efficiency | GPUâ€‘level pragmatism |
| **[Feiâ€‘FeiÂ LiÂ (@drfeifei)](https://x.com/drfeifei)** | Stanford HAI Coâ€‘Director; vision & humanâ€‘centered AI | Humanâ€‘centered research |
| **[MeredithÂ WhittakerÂ (@mwhit)](https://x.com/mwhit)** | President of Signal; coâ€‘founder AIÂ Now Institute | Transparency & governance |
| **[IlyaÂ SutskeverÂ (@ilyasut)](https://x.com/ilyasut)** | Coâ€‘founder & Chief Scientist, OpenAI; superalignment research | Transformer deep dives |
| **[LexÂ FridmanÂ (@lexfridman)](https://x.com/lexfridman)** | Research scientist & longâ€‘form podcaster interviewing AI leaders | Longâ€‘form interviews |
| **[FranÃ§oisÂ CholletÂ (@francois_chollet)](https://x.com/francois_chollet)** | Google Brain researcher; creator of Keras; writes on intelligence | Theoryâ€‘meetsâ€‘practice |
| **[SwyxÂ (@swyx)](https://x.com/swyx)** | Coâ€‘founder SmolÂ AI; devâ€‘infra & agentâ€‘engineering evangelist | Practical infra insights |
| **[TengÂ YanÂ (@0xPrismatic)](https://x.com/0xPrismatic)** | Author of Chainâ€‘ofâ€‘Thought.xyz; bridges AI & crypto ecosystems | AIâ€‘crypto convergence |
| **[ShreyaÂ RajpalÂ (@shreyar)](https://x.com/shreyar)** | Research Partner, a16z; founder GuardrailsÂ AI; MoE evangelist | Safe prompting & MoE |
| **[DarioÂ AmodeiÂ (@darioamodei)](https://x.com/darioamodei)** | Coâ€‘founder & CEO, Anthropic; safety & scaling benchmarks | Frontierâ€‘safety leadership |
| **[MargaretÂ MitchellÂ (@mmitchell_ai)](https://x.com/mmitchell_ai)** | Chief Ethics Scientist, Hugging Face; fairness & bias researcher | Model accountability |
| **[EthanÂ CaballeroÂ (@ethan_caballero)](https://x.com/ethan_caballero)** | Independent MoE & sparsity researcher; open experiments | Constant code drops |
| **[PaulÂ KedroskyÂ (@pkedrosky)](https://x.com/pkedrosky)** | VC at SKÂ Ventures; macroâ€‘economics of AI adoption | Market signal threads |
| **[AnthonyÂ KaszynskiÂ (@akaszynski)](https://x.com/akaszynski)** | Creator PyTorchVideo tutorials; ML educator | Handsâ€‘on tutorials |

---

## 5Â | ğŸŒ Applied CaseÂ Studies
1. **AndromedaÂ Protocol** â€“ AIâ€‘augmented smartâ€‘contract orchestration (CosmosÂ SDK).  
2. **DeepSeekÂ R1** â€“ Edgeâ€‘first design for robotics & IoT.  
3. **GeminiÂ Agents** â€“ Multiâ€‘modal autonomous web workflows (ProjectÂ Astra demo).  

---

## 6Â | âš–ï¸ Ethics, SafetyÂ & Policy
- **OpenAI Preparedness Team** â€“ Catastrophic risk benchmarks.  
- **Anthropic RSP** â€“ Responsible scaling policy v2 (MarÂ 2025).  
- **EUÂ AIÂ Act** passed 13Â MarÂ 2025; tiered compliance for foundation models.  
- **NIST AIÂ RMFÂ 2.0** draft (FebÂ 2025) introduces continuous assurance.

### ğŸ“… Policy Countdown

| Regulation / Policy | Enforcement or Key Milestone | Affects |
|---|---|---|
| EUâ€¯AIâ€¯Act Codes of Practice | **MayÂ 2Â 2025** â€“ draft codes become binding | All frontierâ€‘model providers serving EU |
| Anthropic Responsible Scaling PolicyÂ v2 | **MarÂ 31Â 2025** â€“ threshold checks activated | Claude family deployments |
| NIST AIÂ RMFÂ 2.0 (Draft) | **JulÂ 2025** â€“ public comment closes | US federal procurement |
| UKÂ AI Safety Institute Evaluations | **Q3Â 2025** â€“ initial model eval suite published | Models >Â 10Â¹â´Â params |

---

## 7Â | ğŸ“ Student Opportunities
- **Implementation Checklist**  
  - [ ] Follow all X accounts & enable ğŸ””  
  - [ ] Benchmark three search engines  
  - [ ] Try one creative tool per week  
  - [ ] Replicate GraphÂ RAG tutorial in LangChain  
- **Events & Fellowships**  
  NeurIPS â€¢ CVPR â€¢ AIÂ Engineer Summit â€¢ MITÂ EmTech â€¢ ETHDenver â€¢ DEFCONÂ AIÂ Village â€¢ StanfordÂ HAI Fellowships

---

## 8Â | ğŸ“œ AppendicesÂ & FurtherÂ Reading
### Mandatory Reading
* **Books:** *TheÂ ComingÂ Wave*, *AÂ ThousandÂ Brains*, *HumanÂ Compatible*  
* **Manifestos & Threads:**  
  - SamÂ Altman â€“ *Mooreâ€™s LawÂ forÂ Everything*  
  - YannÂ LeCun â€“ *Energyâ€‘Based Models*

### Advanced Challenges
GroqÂ LPU benchmarks â€¢ Adversarial Claude prompts â€¢ Beat AlphaFoldÂ 3 with OpenFold â€¢ Spoof GPTâ€‘5 via Llamaâ€‘3â€‘400B â€¢ Optimize NVIDIAÂ Blackwell inference

---

*Happy innovating! Pull requests welcome â†’ **#aiâ€‘devâ€‘masterâ€‘list***