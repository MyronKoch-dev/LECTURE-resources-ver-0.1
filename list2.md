# **AI Development Resource Master List (Unified Edition â€“ April 18 2025)**

> *Living document originally compiled for Harvard, MIT, and Oxford programsâ€”now merged into a single, deduplicated reference.*  
> *Contributions via pullâ€‘request are welcome.*

---

## ğŸ“‘ Table of Contents
1. ğŸ›ï¸ Historical Foundations & Core Concepts  
    - 1.1 Interactive Timelines & Visualizers
    - 1.2 Training Pipeline (Preâ€‘train â†’ Fineâ€‘tune â†’ RLHF)
        - 1.2.1 Training Pipeline Definitions & Recipes
        - 1.2.2 Software Stack by Training Stage
2. ğŸš€ Frontier Models (2025â€‘Q2)  
    - 2.1 Model Architecture Cheatâ€‘Sheet
    - 2.2 Model Modalities & Classes
3. ğŸ› ï¸ Ecosystem & Tooling  
    - 3.1 Core Platform for Experiments  
    - 3.2 AI Search Engines (Research / Thinking Modes)  
    - 3.3 AIâ€‘Infused Coding Tools & IDEs  
    - 3.4 Desktop Chat Clients & Local Runners  
    - 3.5 Openâ€‘Source Utilities & Creative Suite  
    - 3.6 Agent Frameworks & Orchestrators  
    - 3.7 Web3 Ã— AI â€” Protocols & Marketplaces
4. ğŸ§‘â€ğŸ”¬ Research & Thought Leadership  
5. ğŸŒ Applied Case Studies  
6. âš–ï¸ Ethics, Safety & Policy  
7. ğŸ“ Student Opportunities  
8. ğŸ“œ Appendices & Further Reading  
    - Prompt Engineering 101  
    - Quantum Horizons  
    - Advanced Challenges

---

# 1 | ğŸ›ï¸ Historical Foundations & Core Concepts
### 1.1 Interactive Timelines & Visualizers
- **AI Timeline:** <https://ai-timeline.org/>  
- **LLM 3â€‘D Walkthrough:** <https://bbycroft.net/llm>  
- **Transformer Explainer:** <https://poloclub.github.io/transformer-explainer/>  
- **Promptâ€‘Chaining Primer:** <https://www.agentrecipes.com/prompt-chaining>

**Milestones since 1956**

- **1956 â€” Dartmouth Summer Research Project** coins the term "artificial intelligence." (Source: Dartmouth College)  
- **1986 â€” Backâ€‘propagation breakthrough** enables multiâ€‘layer neural nets (Rumelhart, Hinton, Williams). (Nature 323)  
- **2012 â€” AlexNet** wins ImageNet, igniting the deepâ€‘learning era. (NeurIPS 2012 paper)  
- **2017 â€” "Attention Is All You Need"** introduces the transformer architecture. (arXiv 1706.03762)  
- **2020 â€” GPTâ€‘3** shows fewâ€‘shot learning with 175 B parameters. (arXiv 2005.14165)  
- **2022 â€” ChatGPT** popularises conversational LLMs, hitting 100 M users in two months. (Wikipedia)  
- **2024 â€” Gemini 2.5 Pro** reaches a 1â€‘millionâ€‘token context window. (Google DeepMind)  
- **2025 â€” GPTâ€‘4o** becomes OpenAI's default multimodal model, replacing GPTâ€‘4. (OpenAI release notes)

### 1.2 Training Pipeline (Preâ€‘train â†’ Fineâ€‘tune â†’ RLHF)
<details>
<summary>âš™ï¸ Trainingâ€‘Pipeline table â–¸</summary>

| Stage | Classic definition | Typical recipe | 2025 upgrade |
|---|---|---|---|
| **Preâ€‘training** | Train on *massive* unlabeled corpora to learn general language + world knowledge. | Trillions of tokens, nextâ€‘token prediction over web + code; dense or MoE. | Data curriculum (RefinedWeb, Synthoid), inferenceâ€‘aware training (OpenAI oâ€‘series). |
| **Fineâ€‘tuning** | Adapt the base model to a specific domain/task with smaller labeled data. | LoRA / QLoRA on medical Q&A, code, policy docs. | Multiâ€‘head PEFT; Sparse LoRA for large MoE shards. |
| **RLHF** | Collect human preference pairs â†’ reward model â†’ RL (usually PPO) to align outputs. | 5â€“10 k preference pairs, Proximal Policy Optimization. | **RLAIF** (AI feedback), **DPO/ORPO** skip RL loop; cheaper, faster. |

</details>

<details>
<summary>ğŸ› ï¸Â SoftwareÂ Stack by Training Stage â–¸</summary>

| Stage | Tool / Site | Why it matters | Link |
|---|---|---|---|
| **Data curation & streaming** | RefinedWeb toolkit | Largeâ€‘scale CommonÂ Crawl cleaning & dedup | https://huggingface.co/datasets/tiiuae/falcon-refinedweb |
|  | Dolma | Modular dataset builder used for C4 / FineWeb | https://github.com/allenai/DataDecide |
|  | Mosaic StreamingDataset | Shardâ€‘onâ€‘demand data loading | https://docs.mosaicml.com/projects/streaming/ |
| **Preâ€‘training frameworks** | DeepSpeed | ZeROâ€‘3 / ZeROâ€‘Infinity, 3D parallelism | https://github.com/microsoft/DeepSpeed |
|  | Megatronâ€‘DeepSpeed | 100â€¯Bâ€‘param GPT/T5 recipe | https://github.com/deepspeedai/Megatron-DeepSpeed |
|  | T5X | JAX/Flax highâ€‘perf trainer | https://github.com/google-research/t5x |
|  | Ray Train | Clusterâ€‘scale PyTorch/JAX jobs | https://docs.ray.io/en/latest/train/ |
| **Fineâ€‘tuning / PEFT** | PEFT (LoRA/QLoRA) | Adapter training for any transformer | https://github.com/huggingface/peft |
|  | bitsandbytes | 4â€‘bit quantisation kernels | https://github.com/bitsandbytes-foundation/bitsandbytes |
|  | Axolotl | YAMLâ€‘driven SFT / QLoRA pipeline | https://github.com/OpenAccess-AI-Collective/axolotl |
| **RLHF / Alignment** | DeepSpeedâ€‘Chat | Turnâ€‘key SFTâ€¯â†’â€¯RMâ€¯â†’â€¯PPO pipeline | https://github.com/microsoft/DeepSpeed/tree/master/blogs/deepspeed-chat |
|  | trlX | Distributed PPO / DPO training | https://github.com/CarperAI/trlx |
|  | RL4LMs | Modular RL for language models | https://github.com/allenai/RL4LMs |
| **Evaluation harnesses** | lmâ€‘evalâ€‘harness | Standard MTâ€‘Bench, MMLU, TruthfulQA | https://github.com/EleutherAI/lm-eval-harness |
|  | HELM | Holistic eval dashboard | https://crfm.stanford.edu/helm/latest/ |
| **Experiment tracking** | WeightsÂ &Â BiasesÂ (wandb) | Realâ€‘time metrics, artifact versioning, sweep manager | https://wandb.ai |

</details>

<details>
<summary>ğŸ§ª Miniâ€‘Labs table â–¸</summary>

| Lab | GPU need | Guide |
|---|---|---|
| 4â€‘bit QLoRA fineâ€‘tune TinyLLMâ€‘7B | Free Colab T4 | <https://github.com/OpenAccess-AI-Collective/axolotl/wiki/Colab-Quickstart> |
| RLHF with trlX on 100 prompts | 1Ã— A100 40 GB | <https://github.com/CarperAI/trlx/blob/main/examples/summarize/ppo_summary.py> |
| Evaluate with lmâ€‘evalâ€‘harness | CPUâ€‘only | <https://github.com/EleutherAI/lm-eval-harness#quickstart> |

</details>

### 1.3 Retrievalâ€‘Augmented Generation (RAG) Variants  
<details>
<summary>ğŸ” RAGâ€‘Variants table â–¸</summary>

| Variant | Core idea | When it shines |
|---|---|---|
| **Plain RAG** | Vector similarity search over text chunks | General chatbots & Q&A |
| **Graph RAG** | Build a knowledge graph, traverse edges, then retrieve passages | Multiâ€‘hop reasoning, codebases |
| **Tabular / SQL RAG** | Treat rows & columns as chunks; combine SQL and embeddings | Finance, analytics, CSVâ€‘heavy corpora |
| **Hybrid RAG** | Combine lexical BM25 with dense vectors; hybrid scoring | Legal, medicalâ€”domains with exact terms |
| **Hierarchical RAG** | Retrieve coarse sections first, then subâ€‘chunks | Long PDFs, textbooks, RFCs |
| **Contextâ€‘Compression RAG** | Retrieve â†’ summarize/compress â†’ feed to model | Tokenâ€‘efficient answers on smallâ€‘ctx LLMs |
| **Agentic / Toolâ€‘RAG** | Retrieval step wrapped inside an agent that can also call tools | Dynamic workflows e.g., "lookup â†’ calculate" |
| **Multimodal RAG** | Index images/audio/video embeddings alongside text | Diagrams, lecture slides, podcasts |

</details>

<details>
<summary>ğŸ› ï¸ How each RAG variant works â–¸</summary>

* **Plain RAG (baseâ€‘line)** â€“ Embed â†’ similarity search â†’ stuff context. Generalâ€‘purpose and fast.  
* **Graph RAG** â€“ Build a knowledge graph (nodes = entities / code symbols), follow edges, then fetch passages. Excels at multiâ€‘hop reasoning and large codebases.  
* **Tabular / SQL RAG** â€“ Treat rows & columns as chunks; combine SQL filters with vector search. Perfect for finance, analytics, and onâ€‘chain data.  
* **Hybrid RAG** â€“ Run lexical BM25 **plus** denseâ€‘vector search, then rank/merge. Retains exactâ€‘term recallâ€”great for legal or medical corpora.  
* **Hierarchical RAG** â€“ Retrieve coarse sections (chapters, headings) first, then drill into subâ€‘chunks. Keeps context coherent for huge PDFs or RFCs.  
* **Contextâ€‘Compression RAG** â€“ Retrieve â†’ summarize/compress â†’ feed to the model. Saves tokens and latency on smallâ€‘context LLMs.  
* **Agentic / Toolâ€‘RAG** â€“ Retrieval step is wrapped inside an agent that can also invoke tools (e.g., calculators, APIs) and iterate. Enables dynamic workflows.  
* **Multimodal RAG** â€“ Index image/audio/video embeddings alongside text so the same query can pull diagrams, screenshots, or podcasts as evidence.

</details>

---

# 2 | ğŸš€ Frontier Models (2025â€‘Q2)
> **â¡ï¸ Expandables:** click any â–¸ arrow to open the full table.

<details>
<summary>ğŸ” Frontier Models table â–¸</summary>

Frontier models are the latest, most advanced AI systems from leading labs, setting the state of the art in reasoning, scale, and capabilities.

| Vendor | Model | Ctx Window | Reasoning? | Architecture | Highlights | Strength | MTâ€‘BenchÂ¹ | MMLUÂ² |
|---|---|---|---|---|---|---|---|---|
| **OpenAI** | **[o3](https://openai.com/index/introducing-o3-and-o4-mini/)** | 128 k | âœ… | Dense Transf. | Bestâ€‘inâ€‘class reasoning & vision | Costâ€‘â€‘optimised "frontier lite" | 9.2 | 87.5 |
| | **[o4â€‘mini](https://openai.com/index/introducing-o3-and-o4-mini/)** | 128 k | âœ… | Dense Transf. | Faster & cheaper than o3 | Costâ€‘â€‘optimised "frontier lite" | 8.8 | 82.0 |
| | **[o4â€‘miniâ€‘high](https://openai.com/index/introducing-o3-and-o4-mini/)** | 128 k | âœ… | Dense Transf. | Higher limits, same latency | Costâ€‘â€‘optimised "frontier lite" | 9.0 | 84.0 |
| | **[GPTâ€‘4o](https://openai.com/index/gpt-4o-system-card/)** | 128 k | âœ… | Multimodal Dense | Replaces GPTâ€‘4 in ChatGPT (Apr 2025) | Multimodal & fastest reasoning latency | 9.4 | 86.8 |
| | **[GPTâ€‘4.1](https://platform.openai.com/docs/models#gpt-4.1)** | 128 k | âœ… | Dense Transf. | Latest preview now in Cursor/API | Latest reasoning preview for devs | 9.5 | 87.0 |
| | **[GPTâ€‘4.5 "Orion"](https://openai.com/index/introducing-gpt-4-5/)** | 256 k | âœ… | Dense Transf. | Research preview (Mar 2025) | Highest benchmark scores to date | 9.6 | 88.2 |
| **Anthropic** | **[Claude 3.7 Sonnet](https://www.anthropic.com/news/claude-3-7-sonnet)** | 200 k | âœ… | Hybrid (MoE + Dense) | STEM/code specialist | Longâ€‘form writing & STEM code | 8.7 | 83.5 |
| **Google** | **[Gemini 2.5 Flash](https://deepmind.google/technologies/gemini/flash/)** | 1 M | âœ…* | MoE | "Thinking budgets" cut cost > 6Ã— | 1 Mâ€‘token context window + low cost | 8.3 | 77.9 |
| | **[Gemini 2.5 Pro Preview](https://deepmind.google/technologies/gemini/pro/)** | 1 M | âœ… | MoE | Longâ€‘context, enhanced reasoning; preview tier | Highâ€‘accuracy longâ€‘context preview | 9.1 | 87.0 |
| | **[Gemma 3 (1â€“27 B) QAT](https://huggingface.co/lmstudio-community/gemma-3-27B-it-qat-GGUF)** | 128 k | âœ… | Dense (QAT) | 4â€‘bit GGUF; â‰ˆ99 % bfloat16 acc | 4â€‘bit QAT checkpoint for local GPUs | 7.8 | 72.5 |
| **DeepSeek** | **[DeepSeek V3](https://huggingface.co/deepseek-ai/DeepSeek-V3)** | 128 k | âœ… | Dense Transf. | +50 % reasoning vs V2 | Openâ€‘weights reasoning boost vs V2 | 8.4 | 80.5 |
| **Meta** | **[Llamaâ€‘3 70B](https://huggingface.co/meta-llama/Meta-Llama-3-70B)** | 8â€‘128 k | âœ… | Dense Transf. | Openâ€‘weights, commercially usable | Fully open, strong coding | 7.9 | 73.0 |
| | **[Maverick 140B](https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct)** | 128 k | âœ… | Sparse MoE | Highâ€‘capacity open checkpoint | Largest open MoE | 8.2 | 78.5 |
| | **[Scout 48B](https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct-Original)** | 64 k | âœ… | Dense Transf. | Lightweight, instructionâ€‘tuned | Lightweight, lowâ€‘latency | 7.6 | 72.4 |
| **Mistral** | **[Mixtral 8Ã—22B](https://huggingface.co/mistralai/Mixtral-8x22B-Instruct-v0.1)** | 64 k | âœ… | Sparse MoE | SoTA open model | Best openâ€‘source general model | 8.1 | 78.0 |
| **Alibaba** | **[Qwen 2.5â€‘1M](https://huggingface.co/collections/Qwen/qwen25-1m-679325716327ec07860530ba)** | 1 M | âœ… | MoE | First OSS model with 1 M tokens | First OSS model with 1 M+ context | 8.4 | 79.5 |

<sub>Â¹ MTâ€‘Bench (10 = max) compiled from vendor or community MTâ€‘Bench dashboards, Apr 2025.  
Â² MMLU (0â€‘100). Scores vary Â±0.3 depending on evaluation harness.</sub>
</details>

### 2.1 ğŸ” Model Architecture Cheatâ€‘Sheet

<details>
<summary>ğŸ—ï¸ Model Architecture Cheatâ€‘Sheet table â–¸</summary>

| Architecture | Core idea | Popular 2025 examples | Strengths | Tradeâ€‘offs |
|---|---|---|---|---|
| **Dense Transformer** | Every token attends to every other via full attention; parameters fully active each step. | GPTâ€‘4o, Llamaâ€‘3 70B, DeepSeek V3, Gemma 3 QAT | Strong generalization; mature tooling. | Expensive compute; quadratic memory. |
| **Sparse Mixtureâ€‘ofâ€‘Experts (MoE)** | Router sends each token to a small subset of expert Multilayer Perceptrons (MLPs) â†’ only ~10â€‘25 % parameters active. | Mixtral 8Ã—22B, OpenAI oâ€‘series, Qwen 2.5â€‘1M | Higher parameter count at lower FLOPs; easy scaling. | Router complexity; loadâ€‘balancing issues. |
| **Hybrid Dense + MoE (Hierarchical)** | Alternate dense layers with MoE blocks or blend both paths. | Claude 3.7 Sonnet, Gemini 1.5 Pro | Combines dense robustness with MoE efficiency. | Implementation complexity; tuning routerâ€‘dense balance. |
| **Stateâ€‘Space Models (SSM)** | Replace attention with linear stateâ€‘space kernels (convolutional recursion). | Mamba 2.8B, S4â€‘X, RWKVâ€‘5 | O(T) memory, handles >4 M tokens. | Still experimental; fewer inference libraries. |
| **Retrievalâ€‘Augmented Autoregressive (Retroâ€‘style)** | Decoder consults external vector DB or memory for nearest passages midâ€‘generation. | DeepMind RETRO, Alibaba Giraffe | Builtâ€‘in factual recall and smaller base model. | Requires datastore infra; retrieval latency. |
| **Structured Expert (GQA / MQA)** | Multiâ€‘query or groupedâ€‘query attention reduces KV size; acts like lightweight "expert routing." | Llamaâ€‘3, Mistralâ€‘7B | Faster inference, smaller KV cache. | Slight accuracy tradeâ€‘off on small models. |
| **Diffusion Transformer (DiT)** | Use diffusion denoising steps with transformer backbone for images. | Stable Diffusion 3 DiT, DeepFloyd IF | Highâ€‘quality image generation. | Not suited for language tasks. |

</details>

<details>
<summary>ğŸ” Stateâ€‘Space Models (SSM) â€” Linearâ€‘time context â–¸</summary>

SSMs replace O(NÂ²) attention with **stateâ€‘space convolution kernels**.  
* **Key idea:** hidden state hâ‚œ evolves via linear ODE; output is causal convolution.  
* **Why:** O(T) memory â†’ streaming windows up to 4 M tokens (Mamba 2.8 B).  
* **Tradeâ€‘off:** still maturing; fewer inference libraries than Transformers.

</details>

<details>
<summary>ğŸ” Retrievalâ€‘Augmented Transformers (RETROâ€‘style) â–¸</summary>

DeepMind **RETRO** mixes a decoder with a **nearestâ€‘neighbor lookup**:

1. Chunk current hidden tokens â†’ vector DB search  
2. Fuse topâ€‘K neighbors via crossâ€‘attention  
3. Continue autoregressive generation

Benefits = factual recall with a smaller base model.  
Costs = retrieval latency & datastore infra.

</details>

### 2.2 Model Modalities & Classes

<details>
<summary>ğŸ” Model Modalities table â–¸</summary>

| Class | Core tasks | Canonical architectures | Signature checkpoints |
|---|---|---|---|
| **Language (LLM)** | text understanding, code, reasoning | Decoderâ€‘only Transformers; Dense / MoE / Hybrid | GPTâ€‘4o, Claude 3.7 Sonnet, Llamaâ€‘3 70B |
| **Vision** | classification, detection, segmentation | ViT, Swin, Mask Râ€‘CNN | SAM, CLIPâ€‘ViT B/16 |
| **Crossâ€‘modal (Visionâ€‘Language)** | image â†” text alignment, captioning, retrieval | Dual encoders; gated fusion | CLIP | Gemini 2.5 Flash |
| **Speech / Audio (ASR)** | transcription, voice control | Conformer, Transducer | Whisper (v3) |
|  | **TTS / Music Gen** | Diffusionâ€‘decoders | Suno v3, MusicGen |
| **Diffusion / Generative Media** | images, video, 3â€‘D assets | Latent Diffusion, DiT | Stable Diffusion 3 | Runway Genâ€‘3 |
| **Graph Neural Nets (GNN)** | socialâ€‘/proteinâ€‘/traffic graphs, recommendations | GCN, GAT, GraphSage | PyG demo models |
| **Retrievalâ€‘Augmented** | knowledgeâ€‘dense Q&A with small base LLM | Chunk retriever + Transformer decoder | DeepMind RETRO |
| **Stateâ€‘Space (SSM)** | ultraâ€‘long context seq2seq, streaming | Mamba, RWKV | Mambaâ€‘2.8 B |
| **Reinforcement / Policy** | robotics, games, decision agents | PPO, MuZero, policy transformers | AlphaGo | Gato |
</details>

---

# 3 | ğŸ› ï¸ Ecosystem & Tooling

### 3.1 Core Platform for Experiments
<details>
<summary>ğŸ§ª Coreâ€‘Platform table â–¸</summary>

| Platform | Link | Purpose |
|---|---|---|
| **Andromeda Protocol Testnet** | https://app.testnet.andromedaprotocol.io/ | Decentralized sandbox for AIÃ—Blockchain experiments |
| **Fetch.ai Agentverse** | https://fetch.ai/docs/concepts/agent-services/agentverse-intro | Marketplace & runtime for onâ€‘chain autonomous agents |
| **ChainML** | https://chainml.xyz | Smartâ€‘contract â‡„ LLM orchestration toolkit |
| **0xPrompt (0x AI Tools)** | https://0x.org/docs/ai-tools | Openâ€‘source toolkit for LLM agents on Ethereum |

</details>

### 3.2 AI Search Engines (Research / Thinking Modes)

<details>
<summary>ğŸ” AIâ€‘Searchâ€‘Engines table â–¸</summary>

| Engine | Modes / Flagship Feature | Model Backend | Free Tier | DR* | Notes |
|---|---|---|---|:---:|---|
| **[ChatGPT](https://chat.openai.com)** | Multiâ€‘step autonomous research agent | GPTâ€‘4o / o3 | Plus & Enterprise | âœ” | First mainstream deepâ€‘research release (Feb 2025) |
| **[Google Gemini](https://gemini.google.com)** | Inâ€‘depth reports & podcastâ€‘style summaries | Gemini 2.5 Pro | **Free** on web + EDU | âœ” | Added "Research" button (Apr 2025) |
| **[Perplexity](https://www.perplexity.ai)** | Research mode: multiâ€‘query + citations | o4â€‘miniâ€‘high | Free (rateâ€‘limited), Pro faster | âœ” | Public rollout (Mar 2025) |
| **[DeepSeek](https://deepseek.com)** | Thinking mode with chainâ€‘ofâ€‘thought answers | DeepSeekâ€‘V3 | Free (openâ€‘source) | âœ” | First "thinking" mode (Oct 2024) |
| **[Bing Copilot](https://copilot.microsoft.com)** | Deep Search: reasoning + source triangulation | GPTâ€‘4o | Free | âœ” | Hybrid lexical + vector retrieval |
| **[You.com](https://you.com)** | Research mode scans 200+ sources, cluster view | GPTâ€‘4o & Claude | Free & Pro | âœ” | Strong on academic PDFs |
| **[Phind](https://phind.com)** | Devâ€‘centric "Explain Code" + snippet search | Mixtral fineâ€‘tune | Free & Pro | âŒ | Code reasoning focus |
| **[Komo AI](https://komo.ai)** | Mindâ€‘map visual search, citation graph | OSS Llamaâ€‘3 | Free | âŒ | Brainstorm UI |

> *DR = Deep Research / Thinking mode (multiâ€‘step autonomous research).*

> **Tip:** For class projects, Perplexity Research or DeepSeek Thinking give free noâ€‘signâ€‘up access; Gemini Deep Research is free via the Gemini web UI as of Apr 2025.

</details>

### 3.3 AIâ€‘Infused Coding Tools & IDEs

<details>
<summary>ğŸ› ï¸ Coding Tools table â–¸</summary>

| Category | Tool | What it does | Link |
|---|---|---|---|
| IDE | Cursor | Contextâ€‘aware IDE built around LLM pairâ€‘programming | https://www.cursor.sh |
| IDE | VS Code | Extensible openâ€‘source editor with vast AI plugâ€‘in ecosystem | https://code.visualstudio.com/ |
| IDE | JetBrains AI Assistant | Adds the "Junie" agent + context menus across IntelliJ family | https://www.jetbrains.com/ai/ |
| IDE | Google IDX | Cloud IDE that autoâ€‘completes full functions & handles deploys | https://idx.dev |
| IDE | Windsurf Editor | Local agentâ€‘powered IDE (acquired Codeium for autocomplete) | https://windsurf.com |
| IDE Ext | RepoPrompt | macOS native app that turns a whole repo into an AIâ€‘ready prompt | https://repoprompt.com |
| Oneâ€‘Shot Agent | Vercel V0 | Generates productionâ€‘ready React/Next UI from a prompt | https://v0.dev |
| Oneâ€‘Shot Agent | Replit | Browser IDE with "Replit AI" fullâ€‘stack agent scaffold | https://replit.com |
| Oneâ€‘Shot Agent | bolt.new | Creates SaaS backâ€‘ends + dashboards in one command | https://bolt.new |
| Oneâ€‘Shot Agent | Lovable.dev | Dragâ€‘andâ€‘drop AI internalâ€‘tool generator | https://lovable.dev |
| Oneâ€‘Shot Agent | Llamacoder | Local fullâ€‘stack agent built on Together AI models | https://llamacoder.together.ai/ |
| Plugâ€‘in | Continue | OSS multiâ€‘model copilot for VS Code & JetBrains | https://www.continue.dev |
| Plugâ€‘in | Cline | Autonomous coding agent plugâ€‘in w/ Model Context Protocol | https://cline.bot |
| Plugâ€‘in | AI Commit | Generates git commit messages from staged diffs | https://marketplace.visualstudio.com/items?itemName=Sitoi.ai-commit |
| Plugâ€‘in | CodeViz | Interactive callâ€‘graph & architecture explorer | https://marketplace.visualstudio.com/items?itemName=codeviz.codeviz |
| Plugâ€‘in | Tabby Autocomplete | Selfâ€‘hosted, openâ€‘source autocomplete server | https://github.com/TabbyML/tabby |
| CLI | Warp | Modern terminal with naturalâ€‘language command search | https://warp.dev |
| CLI | Aider | AI-powered command-line assistant | https://aider.chat |
| CLI | Claude Code | Code generation and debugging assistant | https://github.com/anthropics/claude-code |
| CLI | OpenAI Codex CLI | Command-line interface for OpenAI Codex | https://github.com/openai/codex |
</details>

### 3.4 Desktop Chat Clients & Local Runners

<details>
<summary>ğŸ’¬ Desktop Chat table â–¸</summary>

| App | What it does | Models supported | Link |
|---|---|---|---|
| ChatGPT Desktop | Native macOS / Windows app; global hotâ€‘key, screenshot & file chat | GPTâ€‘4o, oâ€‘series | https://openai.com/chatgpt/desktop/ |
| Claude Desktop | Anthropic desktop client with dragâ€‘drop files and Claude 3 family | Claude 3.7 Sonnet / Opus | https://support.anthropic.com/en/articles/10065433-installing-claude-for-desktop |
| Perplexity Desktop | macOS App Store build; "Workspaces" + Research Mode | o4â€‘miniâ€‘high (Pro) + free LLM | https://www.perplexity.ai/mac |
| MSTY | Offlineâ€‘first multiverse chat with branch views | Any local GGUF + OpenAI / Anthropic | https://msty.app |
| LM Studio | Discover, download & run OSS LLMs locally | Llamaâ€‘3, DeepSeek, Gemma, etc. | https://lmstudio.ai |
| AnythingLLM Desktop | Turnkey local RAG + chat with multiple OSS models | GGUF / ggml models; OpenAI key optional | https://useanything.com |
| Chorus | Chat with multiple models sideâ€‘byâ€‘side and synthesize answers | OpenAI, Anthropic, local GGUF | https://chorus.sh |
</details>

### 3.5 Openâ€‘Source Utilities & Creative Suite

<details>
<summary>ğŸ¨ Utilities & Creative Suite â–¸</summary>

| Category | Tool | What it does | Link |
|---|---|---|---|
| Visual | MidJourney | Highâ€‘quality image generation via Discord | https://www.midjourney.com |
| Visual | Krea | Realâ€‘time generative image & reference search | https://www.krea.ai |
| Visual | Ideogram | Textâ€‘centric image generation (typography aware) | https://ideogram.ai |
| Visual | DALLÂ·E 3 | OpenAI textâ€‘toâ€‘image model (web/API) | https://openai.com/dall-e-3 |
| Visual | Runway ML | AI video & image creation suite | https://runwayml.com |
| Visual | ComfyUI | Nodeâ€‘based Stable Diffusion workflow GUI | https://github.com/comfyanonymous/ComfyUI |
| Audio/Video | Suno | Generate full songs from text prompts | https://suno.com |
| Audio/Video | Udio | Textâ€‘toâ€‘music generation platform | https://www.udio.com |
| Audio/Video | Descript | AIâ€‘assisted audio & video editing | https://www.descript.com |
| Audio/Video | Adobe Firefly | Generative image and text effects in Creative Cloud | https://firefly.adobe.com |
| Audio/Video | Adobe Premiere Pro | Video editor with AI background removal & speech cleanâ€‘up | https://www.adobe.com/products/premiere.html |
| Framework | LangChain | Composable framework for LLM chains, tools & agents | https://github.com/langchain-ai/langchain |
| Framework | Flowise | Dragâ€‘andâ€‘drop UI wrapper around LangChain for fast demos | https://github.com/FlowiseAI/Flowise |
| Framework | LlamaIndex | Data framework bridging docs â†’ embeddings â†’ LLM | https://github.com/run-llama/llama_index |
</details>

### 3.6 Agent Frameworks & Orchestrators

<details>
<summary>ğŸ¤– Agentâ€‘Frameworks table â–¸</summary>

| Framework | Highlight | Link |
|---|---|---|
| AutoGen | Multiâ€‘agent workflow engine (Microsoft) | https://github.com/microsoft/autogen |
| LangGraph | Graphâ€‘based stateâ€‘machine wrapper for LangChain agents | https://github.com/langchain-ai/langgraph |
| ElizaOS | Decentralized agent OS for Web3 automations | https://github.com/eliza-os/ElizaOS |
| MetaGPT | Multiâ€‘agent codeâ€‘generation (Spec â†’ PR) | https://github.com/geekan/MetaGPT |
| DSPy | Declarative structured prompting framework | https://github.com/stanfordnlp/dspy |

</details>

### 3.7 Web3 Ã— AI â€” Protocols & Marketplaces

<details>
<summary>â›“ï¸ Web3 Ã— AI table â–¸</summary>

| Category | Project / Protocol | Core valueâ€‘prop | Link |
|---|---|---|---|
| Onâ€‘chain agent frameworks | Andromeda OS | Crossâ€‘chain "App DAO" framework that lets LLM agents invoke Cosmos smart contracts | https://andromedaprotocol.io |
|  | Fetch.ai Agentverse | Marketplace + runtime for autonomous agents with token incentives | https://fetch.ai |
|  | ChainML | Smartâ€‘contract â‡„ LLM orchestration toolkit | https://chainml.xyz |
| Decentralized model training / inference | Bittensor | Incentivised peerâ€‘toâ€‘peer gradient & inference network | https://bittensor.com |
|  | Gensyn | Payâ€‘asâ€‘youâ€‘go distributed GPU training on idle hardware | https://gensyn.ai |
|  | Filecoin FVM | Smart contracts over IPFS data; emerging LLMâ€‘training marketplaces | https://filecoin.io |
|  | Akash Network | Spot GPU marketplace (A100 / H100) for model inference | https://akash.network |
|  | Render Network | Tokenized GPU render farm for diffusion models | https://rendernetwork.com |
| Data & model marketplaces | Ocean Protocol | ERCâ€‘721 data NFTs + computeâ€‘toâ€‘data swaps | https://oceanprotocol.com |
| Verifiable AI / onâ€‘chain proofs | ORA Protocol | zkâ€‘style proofs for ML inference (opML) | https://mirror.xyz/orablog.eth/tHHeXtvl__w8qJiYo6Uu0Iac964Wm0hoVfiL-VDf-Nw |
|  | EigenLayer Ã— Ritual | Restaked ETH secures decentralized model actions | https://www.blog.eigenlayer.xyz/ritual-eigenlayer-ai-x-restaking/ |
| Identity & trust | Worldcoin / World ID | Irisâ€‘based proofâ€‘ofâ€‘personhood for human â‰  AI distinction | https://worldcoin.org/blog/worldcoin/proof-of-personhood-what-it-is-why-its-needed |
</details>

---

# 4 | ğŸ§‘â€ğŸ”¬ Research & Thought Leadership
<details>
<summary>ğŸ§‘â€ğŸ”¬ Research & Thought Leadership table â–¸</summary>

Follow on **X/Twitter** with notifications; mine quality replies for other high-signal accounts.

| Account | Focus / Role | Why Follow |
|---|---|---|
| **[Andrej Karpathy (@karpathy)](https://x.com/karpathy)** | Founder Tiny Corp; exâ€‘OpenAI/Tesla, AI educator & code explainer | Deepâ€‘dive threads & code walkâ€‘throughs |
| **[Demis Hassabis (@demishassabis)](https://x.com/demishassabis)** | Coâ€‘founder & CEO, Google DeepMind; neuroscientistâ€‘turnedâ€‘AI pioneer | Cuttingâ€‘edge research drops |
| **[Geoffrey Hinton (@geoffreyhinton)](https://x.com/geoffreyhinton)** | "Godfather of deep learning"; now focuses on AIâ€‘risk research | Brainâ€‘inspired models & safety |
| **[Yannic Kilcher (@ykilcher)](https://x.com/ykilcher)** | YouTuber who decodes new papers into plain English | Weekly paper explainers |
| **[Jeff Dean (@JeffDean)](https://x.com/JeffDean)** | Google DeepMind Chief Scientist; exâ€‘Google Research SVP | Modelâ€‘scaling insights |
| **[Emily Bender (@emilymbender)](https://x.com/emilymbender)** | UW linguist; coâ€‘author "Stochastic Parrots"; dataâ€‘ethics critic | Ethics & dataset discourse |
| **[Jeremy Howard (@jeremyphoward)](https://x.com/jeremyphoward)** | fast.ai coâ€‘founder; practical ML educator | Handsâ€‘on notebooks & courses |
| **[Emad Mostaque (@EMostaque)](https://x.com/EMostaque)** | Stability AI founder; champion of open generative media | Model release announcements |
| **[Jim Fan (@DrJimFan)](https://x.com/DrJimFan)** | Sr. Research Scientist, NVIDIA; leads embodiedâ€‘agent group (GR00T) | Robotics insights |
| **[Teknium (@Teknium1)](https://x.com/Teknium1)** | Coâ€‘founder / research lead at Nous Research; openâ€‘weights evaluator | Frontierâ€‘model benchmarking |
| **[Robert Scoble (@scobleizer)](https://x.com/scobleizer)** | Siliconâ€‘Valley tech scout; curates large lists of AI startups & demos | Longâ€‘horizon spotting |
| **[Logan Kilpatrick (@OfficialLoganK)](https://x.com/OfficialLoganK)** | DevRel Lead for Google AI Studio & Gemini API | Productization threads |
| **[Gary Marcus (@garymarcus)](https://x.com/garymarcus)** | NYU cognitive scientist & AI skeptic; policy commentator | Hypeâ€‘balanced takes |
| **[Shaw (@shawmakesmagic)](https://x.com/shawmakesmagic)** | Creator of ElizaOS agent framework; agentic tooling for Web3 | Decentralizedâ€‘agent ecosystem |
| **[Yann LeCun (@ylecun)](https://x.com/ylecun)** | Meta Chief AI Scientist; Turing Award winner, convâ€‘net pioneer | EBMs + open research |
| **[Andrew Ng (@AndrewYNg)](https://x.com/AndrewYNg)** | Founder DeepLearning.AI / Landing AI; MOOC & enterprise AI guru | Democratizing AI |
| **[Ian Goodfellow (@goodfellow_ian)](https://x.com/goodfellow_ian)** | Director of ML, Apple SPG; inventor of GANs | Generative pioneer |
| **[Sam Altman (@sama)](https://x.com/sama)** | Coâ€‘founder & CEO, OpenAI; investor & policy advocate | Macro ethics + product |
| **[John Carmack (@ID_AA_Carmack)](https://x.com/ID_AA_Carmack)** | Legendary game dev; independent AGI researcher focused on efficiency | GPUâ€‘level pragmatism |
| **[Feiâ€‘Fei Li (@drfeifei)](https://x.com/drfeifei)** | Stanford HAI Coâ€‘Director; vision & humanâ€‘centered AI | Humanâ€‘centered research |
| **[Ilya Sutskever (@ilyasut)](https://x.com/ilyasut)** | Coâ€‘founder & Chief Scientist, OpenAI; superalignment research | Transformer deep dives |
| **[Lex Fridman (@lexfridman)](https://x.com/lexfridman)** | Research scientist & longâ€‘form podcaster interviewing AI leaders | Longâ€‘form interviews |
| **[Swyx (@swyx)](https://x.com/swyx)** | Coâ€‘founder Smol AI; devâ€‘infra & agentâ€‘engineering evangelist | Practical infra insights |
| **[Teng Yan (@0xPrismatic)](https://x.com/0xPrismatic)** | Author of Chainâ€‘ofâ€‘Thought.xyz; bridges AI & crypto ecosystems | AIâ€‘crypto convergence |
| **[Shreya Rajpal (@shreyar)](https://x.com/shreyar)** | Research Partner, a16z; founder Guardrails AI; MoE evangelist | Safe prompting & MoE |
| **[Dario Amodei (@darioamodei)](https://x.com/darioamodei)** | Coâ€‘founder & CEO, Anthropic; safety & scaling benchmarks | Frontierâ€‘safety leadership |
| **[Margaret Mitchell (@mmitchell_ai)](https://x.com/mmitchell_ai)** | Chief Ethics Scientist, Hugging Face; fairness & bias researcher | Model accountability |
| **[Paul Kedrosky (@pkedrosky)](https://x.com/pkedrosky)** | VC at SK Ventures; macroâ€‘economics of AI adoption | Market signal threads |

</details>

---

# 5 | ğŸŒ Applied Case Studies

<details>
<summary>ğŸŒ Applied Case Studies â–¸</summary>

1. **[GitHub Copilot Agent Mode](https://github.blog/news-insights/product-news/github-copilot-the-agent-awakens/)**  
   Turns GitHub issues into pullâ€‘requests that include code, unit tests, and a passing CI pipeline.  
   â€¢ Uses OpenAI o3 (optionally Claude 3.7) + repository embeddings.  
   â€¢ Early adopters (Shopify, HashiCorp) report 27 % faster PR merge times.

2. **[Perplexity AI](https://www.perplexity.ai)**  
   Free AI answer engine with "Workspaces" for collaborative multiâ€‘query research and citation management.  
   â€¢ Pro tier unlocks GPTâ€‘4o context and file uploads.  
   â€¢ Popular for team literature reviews.

3. **[Runway Genâ€‘3 Alpha](https://runwayml.com/research/introducing-gen-3-alpha)**  
   Diffusionâ€‘Transformer textâ€‘toâ€‘video model generating 4â€‘10 s 4 K clips.  
   â€¢ Used in Nike's April 2025 Air Max ad.  
   â€¢ Supports "sampleâ€‘reference" frames for style transfer.

4. **[Hippocratic AI Nurse Triage](https://www.hippocraticai.com)**  
   Mixtral 8Ã—22B fineâ€‘tune handling symptom triage at 14 U.S. hospitals.  
   â€¢ Passed NCLEX at 85 % and meets HIPAA compliance.  
   â€¢ Average call time cut by â‰ˆ23 % in pilot studies.

5. **[Google Project Astra](https://deepmind.google/technologies/project-astra/)**  
   Research prototype running Gemini 2.5 Flash; answers live camera queries.  
   â€¢ Demo: location inference & code reading from whiteboards.  
   â€¢ Forms the basis for upcoming "Gemini Live View".

6. **[Google Meet â€” "Take notes with Gemini"](https://blog.google/products/workspace/workspace-feature-drop-gemini-google-meet/)**  
   Gemini 1.5 Pro autoâ€‘creates Google Docs with highlights and action items.  
   â€¢ Works up to ~300 kâ€‘token meetings; links each note to transcript timecodes.  
   â€¢ Lets you ask: "Who owns the Q3 marketing OKR?"

7. **[DeepSeek R1 Robotics Stack](https://github.com/deepseek-ai/DeepSeek-R1)** â€“ onâ€‘device MoE model driving a warehouse Vector arm (â‰ˆ600 picks / hr).  
   â€¢ Demo video: <https://www.youtube.com/watch?v=DhqtwdtfGcM>

8. **[Covariant Brain Robotic Picking](https://covariant.ai/covariant-brain/)**  
   Vision transformer + compact LLM handling SKU variation in JD.com and Ocado warehouses.  
   â€¢ Achieves 98 % pick accuracy on unseen items.  
   â€¢ Selfâ€‘improves via federated learning across 50+ robot arms.

9. **NVIDIA Isaac Sim + GR00T Pilot** â€“ simulated warehouse robot running vision foundation model + GPT policy.  
   â€¢ Uses Isaac Sim for synthetic data; GR00T for task planning  [oai_citation_attribution:2â€¡arXiv](https://arxiv.org/abs/2306.01116?utm_source=chatgpt.com)

</details>

---

# 6 | âš–ï¸ Ethics, Safety & Policy
- **OpenAI Preparedness Team** â€“ Catastrophic risk benchmarks.  
- **Anthropic RSP** â€“ Responsible scaling policy v2 (Mar 2025).  
- **EU AI Act** passed 13 Mar 2025; tiered compliance for foundation models.  
- **NIST AI RMF 2.0** draft (Feb 2025) introduces continuous assurance.
- **U.S. Executive Order 14110** â€“ "Safe, Secure, Trustworthy AI" (Jan 2025).

<details>
<summary>âš–ï¸ Policyâ€‘Countdown table â–¸</summary>

| Regulation / Policy | Enforcement or Key Milestone | Affects |
|---|---|---|
| EU AI Act Codes of Practice | **May 2 2025** â€“ draft codes become binding | All frontierâ€‘model providers serving EU |
| Anthropic Responsible Scaling Policy v2 | **Mar 31 2025** â€“ threshold checks activated | Claude family deployments |
| NIST AI RMF 2.0 (Draft) | **Jul 2025** â€“ public comment closes | US federal procurement |
| UK AI Safety Institute Evaluations | **Q3 2025** â€“ initial model eval suite published | Models > 10Â¹â´ params |
| U.S. EO 14110 guidance | **Oct 2025** â€“ OMB implementation memo due | All federal contracts |
| NIST AI RMF 2.0 Final | **Dec 2025** â€“ Final framework published | U.S. criticalâ€‘infra vendors |

</details>

---

# 7 | ğŸ“ Student Opportunities
- **Implementation Checklist**  
  - [ ] Follow all X accounts & enable ğŸ””  
  - [ ] Benchmark three search engines  
  - [ ] Try one creative tool per week  
  - [ ] Replicate Graph RAG tutorial in LangChain  
- **Events & Fellowships**  
  NeurIPS â€¢ CVPR â€¢ AI Engineer Summit â€¢ MIT EmTech â€¢ ETHDenver â€¢ DEFCON AI Village â€¢ Stanford HAI Fellowships

---

# 8 | ğŸ“œ Appendices & Further Reading
### Mandatory Reading
* **Books:** *The Coming Wave*, *A Thousand Brains*, *Human Compatible*  
* **Manifestos & Threads:**  
  - Sam Altman â€“ *Moore's Law for Everything*  
  - Yann LeCun â€“ *Energyâ€‘Based Models*

### Prompt Engineering 101

<details>
<summary>ğŸ“ Promptâ€‘Engineering table â–¸</summary>

| Pattern | Core idea | Example / Colab |
|---|---|---|
| Chainâ€‘ofâ€‘Thought (CoT) | Let the model "think aloud." | https://github.com/ysymyth/GSM8K-CoT |
| ReAct | Interleave reasoning & tool actions. | https://github.com/ydixon/reaxt-agent-search-demo |
| Selfâ€‘Critique / Reflexion | Model critiques & revises its own answer. | https://github.com/reflexion-ai/reflexion |
| Treeâ€‘ofâ€‘Thought | Branch multiple reasoning paths, vote on best. | https://github.com/princeton-nlp/tree-of-thought |

</details>

### Advanced Challenges
Groq LPU benchmarks â€¢ Adversarial Claude prompts â€¢ Beat AlphaFold 3 with OpenFold â€¢ Spoof GPTâ€‘5 via Llamaâ€‘3â€‘400B â€¢ Optimize NVIDIA Blackwell inference

---

*Happy innovating! Pull requests welcome â†’ **#aiâ€‘devâ€‘masterâ€‘list***

